![Image Description](https://github.com/Tyler-Gustafson/Examining_biases_in_LLMs_causal_analysis/blob/main/01_background/title_page.jpg?raw=true)


# REPORT_Examining_biases_in_LLMs
This report investigates whether large language models (LLMs) exhibit biases when generating socio-economic data based on different racial identities. Using a standardized prompt and controlled variables, we analyze the potential disparities in LLM outputs. Explore our findings and the implications for fairness in AI.
